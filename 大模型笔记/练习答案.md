# 附录 练习答案
## 第1章
1-1. 输出层之前的最后一层（在这个例子中是第二个全连接层）可能对生成嵌入表征最有用。不过，我们也可以使用所有其他中间层来生成嵌入表征。由于后面的层倾向于学习更高级别的特征，因此这些后面的层通常具有更强的语义意义，并且更适用于不同类型的任务，包括相关的分类任务。

1-2. 一种不同于嵌入表征的传统输入表征方法是独热编码，如第1章所述。在该方法中，每个分类变量使用一个二进制向量表示，其中只有一个值是“激活”的（例如，设为1），而所有其他位置都是非激活的（例如，设为0）。
另一种不是嵌入表征的输入形式是直方图。一个典型的示例就是图像直方图（请在维基百科中搜索image histogram）。这些直方图提供了数字图像中色调分布的图形表示，捕获了像素的强度分布。
此外，词袋模型提供了另一种不同于嵌入表征的方法。在这类模型中，输入的句子被表示为其词语的无序集合或“词袋”，而不考虑语法甚至语序。有关词袋模型的更多详细信息，请参阅维基百科。

## 第2章
2-1. 将自监督学习应用于视频数据的一种方式是预测视频中的下一帧。这类似于GPT等大模型中的下一个词预测。该方法对模型提出了挑战，模型要能够预测序列中的后续事件或动作，从而对内容产生时序上的理解。
另一种方法是预测缺失或被遮罩的帧。这个想法是从大模型（如BERT）中获得的灵感，其中某些词会被遮罩起来，模型的任务是预测它们。对于视频而言，可以将整帧画面遮罩起来，模型则学会根据周围帧所提供的上下文来插值并预测被遮罩的帧。
图像修复是视频领域自监督学习的另一种途径。这里，不是遮罩整个帧，而是在帧内特定的像素区域进行遮罩，然后训练模型来预测缺失或被遮罩的部分，这有助于模型把握视频内容中的细粒度视觉细节和空间关系。
最后，可以使用着色技术，即把视频转换成灰度图像，然后让模型预测颜色。这不仅能教会模型识别物体原本的颜色，还能让模型了解到光线、阴影以及场景的整体氛围。

2-2. 我们可以移除（遮罩）特征值，并训练模型来预测这些值，这类似于经典的缺失值填补方法。例如，采用这种方式的一个方法是TabNet；参见Sercan O. Arik和Tomas Pfister的论文“TabNet: Attentive Interpretable Tabular Learning”（2019）。
还可以通过在原始特征空间或嵌入空间中生成训练样本的增强版本来进行对比自监督学习。例如，SAINT和SCARF方法就采用了这种做法。对于前者，请参阅Gowthami Somepalli等人的文章“SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training”（2021）。对于后者，请参阅Dara Bahri等人的文章“SCARF: Self-Supervised Contrastive Learning Using Random Feature Corruption”（2021）。

## 第3章
3-1. 与监督学习类似，我们先将数据集划分为训练集和测试集，然后进一步将训练集和测试集划分为子集，每个分类中有一张图像。为了设计训练任务，我们只考虑分类的一个子集，例如分类（数字）0,1,2,5,6,8,9。接下来，在测试时，我们使用剩余的分类3,4,7。对于每个分类任务，神经网络仅接收每张图像的一个样本。

3-2. 考虑罕见疾病的医学影像场景。训练数据集可能只包含几种疾病的少量样本，并且对于新的、未知的罕见疾病（不包含在训练集中），小样本系统可能只有一个或几个病例。因此任务就是基于这数量有限的样本来识别新的罕见疾病。
小样本系统的另一个例子是推荐系统，它只有用户评价过的少量样本。基于有限的样本，模型必须预测用户未来可能喜欢的产品。想象一下，当一家公司增加库存时，仓库机器人必须学会识别新的物品。机器人必须仅基于几个样本来学会识别和适应这些新物品。

## 第4章
4-1. 你可以尝试增大原始神经网络。可能是所选的网络太小，无法包含合适的子网络。
另一种选择是尝试不同的随机初始化方式（例如更改随机种子）。彩票假设认为某些随机初始化的网络中包含可以通过剪枝获得的高精度子网络，但并非所有网络都会有这样的子网络。

4-2. 当使用ReLU激活函数训练神经网络时，如果函数输入小于0，则特定激活将设为0。这会导致隐藏层中的某些节点不参与计算。这些节点有时被称为死亡神经元。虽然ReLU激活并不直接导致权重稀疏，但零激活输出有时会导致不可恢复的零权重。这一现象支持了彩票假设，该假设认为，经过良好训练的网络可能包含具有稀疏、可训练权重的子网络，这些子网络可以在不损失准确性的情况下进行剪枝。

## 第5章
5-1. XGBoost是一种基于树的梯度提升的实现方式，在撰写本文时，它还不支持迁移学习。与人工神经网络相比，XGBoost是一种非参数模型，我们不能在新数据到达时随时更新它。因此，常规的迁移学习在这里不起作用。
不过，可以将一个XGBoost模型在一个任务上训练得到的结果作为另一个XGBoost模型的特征来使用。考虑两个数据集之间有一组重叠的特征。例如，我们可以为组合数据集设计一个自监督分类任务。然后，我们可以用目标数据集训练第二个XGBoost模型，该模型以原始特征以及第一个XGBoost模型的输出作为输入。

5-2. 在应用数据增强时，通常也需要增加训练时间。我们可能需要对模型进行更长时间的训练。
另外，也有可能对数据增强过度。过度增强数据可能会导致超出数据自然变化范围的一些过度变化，从而导致对新数据过拟合或较差的泛化性。如果是MNIST数据集，还可能包括平移或裁剪图像，以至于数字因缺失部分而变得无法识别。
另一种可能是用了过于简单、不符合领域特点的数据增强。例如，假设我们对图像进行水平或垂直翻转。对于MNIST来说，这是没有意义的，因为对手写数字进行水平或垂直翻转会产生现实中不存在的数字。

## 第6章
6-1. 调整训练轮数是一种更简单、更通用的方法。这一点对于那些不支持模型检查点的老式框架尤其适用。因此，改变训练轮数可能是一种更简单的解决方案，并且对于小型数据集和每次超参数配置运行及评测成本较低的模型特别有吸引力。这种方法还不需要在训练过程中监控模型在验证集上的性能，因而简单易用。
当使用训练成本较高的模型时，早停法和检查点法都特别有用。通常这也是更灵活、更稳健的减少过拟合的方法。然而，这种方法的缺点是，在有噪声的训练方案中，即使验证集上的准确度不能很好地估计泛化准确度，我们也可能会优先选择较早的训练轮次。

6-2. 集成方法的一个明显缺点是计算成本增加了。例如，如果我们构建一个由五个神经网络组成的神经网络集成，则该集成的成本可能是单个模型的五倍。
虽然我们经常考虑上述提到的推理成本，但存储成本的增加也是另一个重要的限制因素。如今，大多数计算机视觉和语言模型有数百万甚至数十亿个参数，这些参数必须存储在分布式环境中。模型集成使这进一步复杂化。
可解释性的下降，是我们进行模型集成时面临的另一个代价。理解和分析单个模型的预测结果已经很有挑战性了。根据集成方法的不同，我们又增加了另一层复杂性，进一步降低了可解释性。

## 第7章
7-1. Adam优化器实现了一种带有内部权重参数的自适应方法。Adam优化器的每个模型参数有两个优化器参数（均值和方差），因此不仅要分割模型的权重张量，还要分割优化器的状态以解决内存限制问题。（请注意，这已经在大多数DeepSpeed并行技术中实现了。）

7-2. 理论上，数据并行可以在CPU上工作，但其优势也会受限。例如，与其在CPU内存中复制模型，并行地在数据集的不同批次上训练多个模型，不如提高数据吞吐量。

## 第8章
8-1. 由于自注意力机制需要进行$n$到$n$的比较（其中$n$是输入序列的长度），因此它在计算和内存复杂度上是平方级的，这使得与其他神经网络架构相比，Transformer的计算成本很高。此外，解码器类型的Transformer（如GPT）一次输出一个词元，在推理期间不能并行化（尽管生成每个词元仍然是高度并行的，如第8章所述）。

8-2. 我们可以将自注意力视为特征选择的一种形式，尽管这种特征选择与其他类型的特征选择之间存在差异。在这个背景下，区分硬注意力和软注意力是很重要的。软注意力计算所有输入的重要性权重，而硬注意力则选择输入的一个子集。硬注意力更像是在掩蔽，其中的某些输入被设置为0或1，而软注意力允许重要性分数有连续的变化范围。注意力和特征选择的主要区别是，特征选择通常是固定的操作，而注意力权重是基于输入动态计算的。使用特征选择算法时，所选特征总是相同的，而对于注意力来说，权重可以根据输入发生变化。

## 第9章
9-1. 自动进行此评测，本质上是困难的，目前的黄金标准仍然基于人类的评估和判断。不过，确实存在一些作为定量衡量指标的方法。
为了评测生成图像的多样性，可以使用KL散度正则项来比较生成样本的条件类分布和边缘类分布。该度量也用于VAE中，以使潜空间向量接近标准高斯分布。KL散度越高，生成图像的多样性就越丰富。
也可以将生成图像的统计特性与预训练模型（如用作图像分类器的卷积网络）特征空间中的真实图像进行比较。高度相似（或距离较近）表示两个分布彼此接近，这通常是图像质量更好的标志。这种方法通常称为Fréchet起始距离法。

9-2. 与GAN、VAE或者扩散模型的生成器一样，一致性模型也接受从简单分布（如标准高斯分布）中采样的噪声张量作为输入，并生成新图像。

## 第10章
10-1. 能，通过设置$k=1$，我们可以使top-$k$采样具有确定性，以便模型在生成输出文本时，始终选择概率分数最高的词作为下一个词。
我们也可以让核采样具有确定性，例如通过设置概率质量阈值$p$，使之只包含一个元素，该元素正好满足或超过该阈值。这将使模型始终选择概率最高的词元。

10-2. 在某些情况下，推理过程中Dropout的随机行为可能是有好处的，例如使用单个模型构建模型集成。（如果没有Dropout中的随机行为，模型将为给定的输入产生完全相同的结果，这会使集成变得多余。）
此外，Dropout中的随机推理行为可以用于稳健性测试。对于医疗保健或自动驾驶等关键应用，了解模型的微小变化如何影响其预测是至关重要的。通过使用随机Dropout模式，我们可以模拟这些微小的变化，并测试模型的稳健性。

## 第11章
11-1. SGD只有学习率这一个超参数，没有任何其他参数。因此，除了在反向传播期间为每个权重参数计算的梯度（包括计算梯度所需的层激活），它不会增加任何需要存储的额外参数。
Adam优化器更复杂，且需要更多的存储空间。具体来说，Adam优化器为每个参数保留了过去梯度（一阶矩）的指数衰减平均值和过去平方梯度（二阶原始矩）的指数衰减平均值。因此，对于网络中的每个参数，Adam优化器需要存储两个额外的值。如果网络中有$n$个参数，则Adam优化器需要存储$2n$个额外的参数。
如果网络有$n$个可训练参数，Adam优化器将添加$2n$个要追踪的参数。例如，在由26926个参数组成的AlexNet中，如练习1-1中计算的，Adam优化器总共需要53852（2×26926）个附加值。

11-2. 每个BatchNorm层在训练期间学习两组参数：一组缩放系数（gamma）和一组偏移系数（beta）。学习这些参数的目的是让模型能够在发现归一化对学习起负面作用时，取消归一化的效果。这些参数集（gamma和beta）的大小与它们所归一化的层中的通道数（或神经元数）相同，因为这些参数是为每个通道（或神经元）单独学习的。
对于第一个卷积层之后的第一个BatchNorm层，具有5个输出通道，就会添加10个额外的参数。对于第二个卷积层之后的第二个BatchNorm层，第二个卷积层具有12个输出通道，就会添加24个额外的参数。
第一个全连接层有128个输出通道，这意味着需要256个额外的BatchNorm参数。第二个全连接层没有BatchNorm层，因为它本身就是输出层。
因此，BatchNorm将10+24+256=290个附加参数添加到网络中。

## 第12章
12-1. 仅将步幅从1增加到2（或更大值）不应影响等价性，因为在这两种情况下，卷积核大小都等于输入大小，所以这里并没有滑动窗口机制。

12-2. 填充增加大于0的值会影响结果。由于输入进行了填充，我们会得到滑动窗口的卷积操作，这时与全连接层的等价性不再成立。换句话说，填充会改变输入的空间维度，导致与卷积核的大小不再匹配，并将导致每个特征映射有多个输出值。

## 第13章
13-1. 使用较小的图像块会增加给定输入图像的图像块数量，从而导致更多的词元被送入Transformer。这会导致计算复杂度增加，因为Transformer中的自注意力机制相对于输入词元的数量具有二次方的复杂度。因此，较小的输入图像块会使模型的计算成本更高。

13-2. 使用较大的输入图像块可能会导致输入图像中细微的细节和局部结构丢失，这可能会对模型的预测性能产生负面影响。感兴趣的读者可能会想阅读FlexiViT论文，该论文研究了因图像块大小及数量不同而引起的计算性能和预测性能之间的权衡（Lucas Beyer et al.,“FlexiViT: One Model for All Patch Sizes”[2022]）。

## 第14章
14-1. 因为同音异义词有不同的含义，所以我们会希望它们出现在不同的语境中，例如“I can see you over there”$^{①}$和“Their paper is very nice”$^{②}$中的“there”和“their”$^{③}$。
由于分布假设认为含义相似的词应该出现在相似的语境中，因此同音词并不与分布假设相矛盾。

14-2. 分布假设的基本思想可以应用于其他领域，如计算机视觉。在图像场景下，出现在相似视觉场景中的对象很可能在语义上是相关的。在更低的级别，相邻像素可能在语义上相关，因为它们是同一对象的一部分。该思想用于图像数据自监督学习中的掩蔽自编码器。（我们在第2章中介绍过掩蔽自编码器。）
另一个例子是蛋白质的建模。举例来说，研究人员发现，在蛋白质序列（其中每个字母代表一种氨基酸的字符表示形式，如MNGTEGPNFYVPFSNKTGTV…）上训练的语言Transformer模型学习的嵌入，会将相似的氨基酸聚类到一起（Alexander Rives等人所著的“Biological Structure and Function Emerge from Scaling Unsupervised Learning to 250 Million Protein Sequences”[2019]）。疏水性氨基酸（如V、I、L和M）出现在一个聚类中，芳香族氨基酸（如F、W和Y）则出现在另一个聚类中。在这种情况下，我们可以认为氨基酸相当于句子中的词语。

**注**：①意为：我可以看到你在那边。②意为：他们的论文非常好。③“there”和“their”在英语中读音相同。

## 第15章
15-1. 假设现有数据不存在隐私问题，数据增强有助于在不需要收集额外数据的情况下生成现有数据的变体，这有助于解决隐私问题。
然而，如果原始数据包括个人可识别信息，那么即使是经过增强或合成的数据也可能被追溯回特定个体，尤其是增强过程没有充分地模糊或改变原始数据时。

15-2. 如果原始数据集足够大、足够多样化，让模型不会由于缺乏数据而过拟合或性能不佳，那么数据增强可能没那么大用处。例如，对大模型进行预训练时，通常就是这种情况。
高度特定于领域（如医学、法律和金融领域）的模型，性能也可能受到同义词替换和回译等技术的负面影响，因为这些技术可能会将具有特定含义的领域术语替换掉。通常，在对措辞选择高度敏感的任务语境中，应用数据增强时必须特别小心。

## 第16章
16-1. 自注意力机制的时间和空间复杂度是二次方的。更确切地说，我们可以将自注意力的时间和空间复杂度表达为$O(N^2×d)$，其中$N$是序列长度，$d$是序列中每个元素嵌入的维度。
这是因为自注意力涉及计算序列中每对元素之间的相似度得分。例如，我们有一个有$N$个词元（行）的输入矩阵$X$，其中每个词元都是$d$维嵌入（列）。
当计算每个词元嵌入到其他词元嵌入的点积时，我们乘以$XX^T$，会得到一个$N×N$的相似度矩阵。该乘法涉及单个词元对的$d$次乘法，共有$N^2$个这样的词元对。因此，复杂度为$O(N^2×d)$。然后利用这个$N×N$相似矩阵来计算序列元素的加权平均值，从而得到$N×d$输出表征。这会使自注意力计算成本较高且占用大量内存，尤其是在序列较长或$d$的值较大时。

16-2. 确实如此。有趣的是，自注意力机制可能部分受到了用于图像处理的卷积神经网络中空间注意力机制的启发（Kelvin Xu等人所著的“Show, Attend and Tell: Neural Image Caption Generation with Visual Attention”[2015]）。空间注意力是一种允许神经网络专注于图像中与特定任务相关区域的机制。它有选择地为图像中不同空间位置的重要性加权，从而使网络能够“更多地关注”某些区域而忽略其他区域。

## 第17章
17-1. 要将预训练的BERT模型用于分类任务，需要添加用于分类的输出层，通常称为分类头。
正如前面讨论过的，BERT在预训练期间使用词来执行下一句预测任务。我们不必对其进行预测下一句的训练，而是可以为我们的目标预测任务（如情感分类）微调新的输出层。
嵌入的输出向量充当整个输入序列的摘要。我们可以将其视为一个特征向量，并在其上训练一个小型神经网络，通常是一个全连接层接一个softmax激活函数来预测分类概率。全连接层的输出大小应与我们分类任务中的分类数量相匹配。然后我们可以像往常一样使用反向传播来训练它。比如，可以使用不同的微调策略（更新所有层而不是仅更新最后一层）在监督数据集上训练模型。

17-2. 是的，我们可以对像GPT这样的纯解码器模型进行微调来执行分类任务，尽管它可能不如像BERT这样的基于编码器的模型有效。与BERT相比，我们不需要使用特殊的，但基本概念类似于微调编码器模型以执行分类任务。我们添加一个分类头（一个全连接层和一个softmax激活函数），并在生成的第一个输出词元的嵌入（最终隐藏状态）上对其进行训练（这类似于使用

# 附录 练习答案（续）
### 第17章（续）
17-2. 是的，我们可以对像GPT这样的纯解码器模型进行微调来执行分类任务，尽管它可能不如像BERT这样的基于编码器的模型有效。与BERT相比，我们不需要使用特殊的`[CLS]`词元，但基本概念类似于微调编码器模型以执行分类任务。我们添加一个分类头（一个全连接层和一个softmax激活函数），并在生成的第一个输出词元的嵌入（最终隐藏状态）上对其进行训练（这类似于使用`[CLS]`词元的嵌入）。

### 第18章
18-1. 如果我们无法访问模型，或者我们想要使模型适应那些未曾训练过的类似任务，上下文学习是有用的。
相比之下，微调对于使模型适应新的目标领域是有用的。例如，假设模型在通用语料库上预训练的，并且我们希望将其应用于金融数据或文档。在这里，对来自该目标领域的数据进行模型微调是有意义的。
请注意，上下文学习也可以与微调模型一起使用。例如，当一个预训练的语言模型在一个特定任务或领域上进行微调后，上下文学习利用模型根据输入中提供的上下文生成响应的能力。与不进行微调的上下文学习相比，在给定目标领域的情况下，该模型生成的响应可能更准确。

18-2. 这是隐式完成的。在前缀调优、适配器和LoRA中，预训练语言模型原有的知识被保留下来，这是通过在保持核心模型参数冻结的同时，引入额外可学习的参数来适应新任务实现的。

### 第19章
19-1. 如果使用像Word2vec这样独立处理每个词语的嵌入技术，我们预期“cat”的嵌入之间的余弦相似度是1.0。然而，在这种情况下，我们使用Transformer模型来生成嵌入。Transformer使用自注意力机制，在生成嵌入向量时会考虑整个上下文（例如输入文本）。（有关自注意力的更多信息，请参阅第16章。）由于单词cat用于两个不同的句子，BERT模型为这两个cat的样本生成了不同的嵌入。

19-2. 交换候选文本和参考文本，与计算列与行之间的最大余弦相似度具有相同的效果（如图19-3中的步骤5所示），可能会导致特定文本的BERTScore不同。这就是为什么在实践中，BERTScore通常被计算为类似于ROUGE的F1分数。例如，我们会先按一种方式计算BERTScore（召回率），然后再按另一种方式计算（准确度），最后计算调和平均值（F1分数）。

### 第20章
20-1. 基于CART决策树的随机森林通常不能随着新数据的到来而随时更新。因此，无状态训练方法是唯一可行的选择。如果我们转而使用如循环神经网络这样的神经网络模型，有状态方法可能更有意义，因为神经网络可以随时根据新数据进行更新。（不过，最好一开始就横向比较有状态系统和无状态系统，以决定哪种方法最有效。）

20-2. 有状态的重训练在这里最有意义。与其在结合现有数据（包括用户反馈）的基础上训练一个新模型，不如基于用户反馈更新模型。大模型通常以自监督的方式预训练，然后通过监督学习进行微调。训练大模型的成本是非常高的，因此通过有状态的重训练来更新模型比从头开始重新训练模型更有意义。

### 第21章
21-1. 从提供的信息来看，还不清楚这是否是一种以数据为中心的方法。人工智能系统在很大程度上依赖数据输入来做出预测和提出建议，但对于任何人工智能/机器学习方法来说都是如此。为了确定这种方法是否是以数据为中心的人工智能的例子，我们需要知道人工智能系统是如何开发的。如果它是通过使用固定的模型并对训练数据进行改进来开发的，这称得上是一种以数据为中心的方法；否则，只是常规的机器学习和预测建模。

21-2. 如果我们保持模型不变，也就是说重用相同的ResNet-34架构，并且只改变数据增强方法来探究其对模型性能的影响，那么我们可以认为这是一种以数据为中心的方法。然而，数据增强也是现代机器学习流水线中的常规流程之一，仅仅是使用数据增强方法本身并不能说明这种方法是否是以数据为中心的。根据现代定义，以数据为中心的方法要在保持其余的模型构建和训练流水线不变的情况下，积极研究各种数据增强技术之间的差异。

### 第22章
22-1. 使用多GPU策略进行推理的一个缺点是GPU之间的额外通信开销。然而，对于推理任务来说，因为它们不需要梯度计算和更新，相较于训练而言规模较小，所以GPU之间的通信时间可能会超过并行化节省的时间。
管理多个GPU也意味着更高的设备和能耗成本。在实践中，以提升单个GPU或CPU性能为目的来优化模型通常更值得。如果有多个GPU可用，在不同的GPU上并行处理多个样本要比使用多个GPU处理同一个样本更为合理。

22-2. 循环分块通常与向量化结合使用。例如，在应用循环分块之后，可以使用向量化操作来处理每个分块。这让我们能够对缓存中已经存在的数据使用SIMD指令，从而提高这两种技术的有效性。

# 附录 练习答案
## 第23章
23-1. 问题是，重要性加权假设测试集分布与部署分布相匹配。然而，由于各种原因，这往往并非实际情况，比如不断变化的用户行为、不断发展的产品功能或动态的环境。

23-2. 通常我们会监控分类准确度等指标，性能下降可能表示数据发生了变化。然而，如果我们无法获取到新流入数据的标签，这样做是不切实际的。
在无法标记新流入数据的情况下，我们可以使用统计双样本检验来确定样本是否来自同一分布。我们还可以使用对抗验证，如第29章所述。然而，这些方法无助于检测概念偏移，因为它们只比较输入分布，而不比较输入与输出之间的关系。
其他方法包括测量重建误差：如果我们有一个在源数据上训练好的自编码器，就可以监控新数据上的重建误差。如果误差显著增大，则可能表示输入分布发生了变化。
异常检测是另一种常见的技术。当被识别为异常值的数据点的比例异常高时，表明数据分布可能发生了变化。

## 第24章
24-1. 尝试预测一名球员进球的数量（例如，基于过去几个赛季的数据）是一个泊松回归问题。我们也可以应用序回归模型，根据进球数量对球员进行排名。
然而，由于进球差是恒定的，并且可以量化（例如，3个进球和4个进球之间的差别与15个进球和16个进球之间的差别相同），因此对于序回归模型来说，这不是一个理想的问题。

24-2. 这是一个类似于序回归问题的排序问题，但存在一些差异。由于我们只知道电影的相对顺序，因此与序回归模型相比，成对排序算法可能是更合适的解决方案。
然而，如果要求此人按1到5的范围（类似于亚马逊网站上的星级评价系统）为每部电影分配数字标签，那么有可能在这种类型的数据上训练并使用序回归模型。

## 第25章
25-1. 置信水平（90%、95%、99%等）的选择会影响置信区间的宽度。较高的置信水平会产生较宽的区间，因为我们需要撒一个更大的网，以更加确信我们捕捉到了真实的参数。
相反，较低的置信水平产生较窄的区间，反映了关于真实参数所在位置的更大的不确定性。因此，90%的置信区间比95%的置信区间窄，反映出对真实总体参数的位置有更大的不确定性。通俗地说，我们90%确信真实参数位于一个较小的值范围内。为了增加这种确定性，我们必须将区间宽度增加到95%或99%。
例如，假设我们90%确定威斯康星州未来两周将下雨。如果我们想在不收集额外数据的情况下做出95%置信度的预测，就必须增加时间间隔。例如，我们可能会说有95%的把握确定在未来四周内会下雨，或者有99%的把握确定在未来两个月内会下雨。

25-2. 由于模型已经过训练并且保持不变，因此将其用于每个测试集将是浪费。为了加快本节中介绍的过程，从技术上讲，我们只需要将模型应用一次，即应用到原始测试集上。然后，我们可以直接自助采样实际标签和预测标签（而不是原始样本）来创建自助采样测试集。接下来，我们可以基于每个测试集中的自助采样标签来计算测试集准确度。

## 第26章
26-1. 预测集合的大小可以告诉我们很多关于预测确定性的信息。如果预测集合很小（例如，在分类任务中为1），则表明对预测有很高的信心。该算法有足够的证据强烈提示出一种特定的结果。
如果预测集合较大（例如，在分类任务中为3），则表示更大的不确定性。该模型对预测的信心较低，并认为多个结果是可信的。在实践中，我们可以利用这些信息为预测集合大小较大的样本分配更多的资源。例如，我们可以将这些案例标记出来供人工审核，因为机器学习模型对此不太确定。

26-2. 当然可以。置信区间同样适用于回归模型，就像它们适用于分类模型一样。事实上，它们在回归的背景下更加通用。例如，我们可以使用第25章中介绍的方法来计算模型性能（如均方误差）的置信区间。（但我们也可以计算单次预测结果和模型参数的置信区间。如果你对模型参数的置信区间感兴趣，请参阅我的文章“Interpretable Machine Learning—Book Review and Thoughts about Linear and Logistic Regression as Interpretable Models”。）
我们还可以计算回归模型的共形预测区间。这个区间是一系列可能的目标值，而不是单一的点估计。对这种预测间隔的解释是，假设在统计上未来与过去相似的前提下（例如，基于模型训练所使用的数据），新实例的真实目标值将以一定的置信水平，例如95%，落在这个区间范围内。

## 第27章
27-1. 由于MAE是基于距离的绝对值计算的，因此它自然满足第一个标准：它不能为负。
此外，如果我们将$y$和$\hat{y}$的值互换，MAE相同，因此，它满足第二个条件。那三角不等式呢？类似于RMSE与欧氏距离或L2范数相同，MAE类似于两个向量之间的L1范数。由于所有向量范数都满足三角不等式（Horn and Johnson, *Matrix Analysis*, Cambridge University Press, 1990），我们同事的说法是不正确的。
此外，即使MAE不是合适的距离度量，它仍然可以作为一个有用的模型评测指标，比如可以考虑分类准确度。

27-2. MAE为所有误差分配相等的权重，而RMSE由于平方指数的原因，对绝对值较大的误差给予更多的重视。因此，RMSE总是至少与MAE一样大。然而，没有哪一个指标普遍优于另一个指标，多年来两者都被用于评测模型性能的无数研究中。
如果你对MAE和RMSE之间的进一步比较感兴趣，可能会喜欢Cort J. Willmott和Kenji Matsuura的文章：“Advantages of the Mean Absolute Error (MAE) Over the Root Mean Square Error (RMSE) in Assessing Average Model Performance”(2005)。

## 第28章
28-1. 如果我们只关心平均性能，这不是问题。例如，我们有一个包含100个训练样本的数据集，并且模型正确地预测了100个验证折中70个，则我们估计模型的准确度为70%。然而，假设我们有兴趣分析不同折的估计值的方差，那么LOOCV就不是非常有用了，因为每个折仅有一个训练样本，所以我们不能计算每个折的方差，并将之与其他折进行比较。

28-2. $k$折交叉验证的另一个应用场景是模型集成。例如，在5折交叉验证中，我们训练五个不同的模型，因为我们有五个略有不同的训练集。然而，我们不必在整个训练集上训练一个最终模型，而是可以将五个模型组合成一个模型集成（这在Kaggle上特别流行）。有关该过程的说明，请参见图6-3。

## 第29章
29-1. 作为性能基准，实现零规则分类器是个好主意，例如多数类分类器。由于我们通常拥有比测试数据更多的训练数据，因此可以计算一个总是预测“是否测试数据？”为“否”的模型的性能，如果我们将原始数据集划分为70%的训练数据和30%的测试数据，则应是70%的准确度。如果在对抗验证数据集上训练的模型的准确率明显超过了这个基线（例如，80%），我们可能需要进一步排查一个严重的不一致性问题。

29-2. 总的来说，这不是一个大问题，因为我们主要关注是否与多数分类预测基线有明显的偏差。例如，如果我们将对抗性验证模型的准确度与基线（而不是50%的准确度）进行比较，就不会有问题。然而，与分类准确度相比，评测指标使用如Matthew相关系数、ROC或准确度召回曲线这类AUC（area-under-the-curve，曲线下面积）数值可能会更好。

## 第30章
30-1. 虽然我们通常将自监督学习和迁移学习视为不同的方法，但它们并不一定是相斥的。
例如，我们可以使用自监督学习在已打标或更大的未打标图像数据集上预训练模型（在这种情况下，对应于各种计算设备的数百万张未打标图像）。
我们可以使用来自自监督学习的神经网络权重，而不是从随机权重开始，接着通过数千张打标过的智能手机图片进行迁移学习。由于智能手机与平板电脑相关，迁移学习在这里是一个非常有潜力的方法。
最后，在自监督预训练和迁移学习完成后，我们可以在目标任务的数百张有标签图像上对模型进行微调，这里是平板电脑的图像。

30-2. 除了针对神经网络输出层产生的过度自信分数的缓解技术外，我们还可以考虑采用多种集成方法来获得置信分数。例如，我们可以在推理过程中利用Dropout而不是禁用它，以获得一个样本的多个不同预测结果，进而计算预测标签的不确定性。
另一种选择是使用第6章中讨论的$k$折交叉验证，从训练集的不同部分构建模型集成。
也可以将第26章中讨论的共形预测方法应用于主动学习。

我可以帮你把这些练习答案按**知识点类别**整理成一份速查清单，方便你快速对应章节和核心考点，需要吗？
