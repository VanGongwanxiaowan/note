
### 核心背景
当机器学习模型出现过拟合，且能从更多训练数据中受益，但无法收集更多数据时，可通过一系列方法在有限有标签数据下提升模型性能。

### 具体方法及核心内容
1. **标注更多数据**
    - 收集更多训练样本是提升性能的最佳方法，但实践中常因成本、资源、数据获取难度等不可行。
2. **自助抽样数据**
    - 生成修改/人工合成的训练样本（数据增强、自助重抽样），减少过拟合，提升预测性能，同时提升数据质量也能增强模型预测性。
3. **迁移学习**
    - 先在通用数据集（如ImageNet）上预训练模型，再在小样本的目标数据集上微调；多在深度学习中进行（模型权重可更新），与非参数的决策树算法形成对比（图30-1展示迁移学习过程）。
4. **自监督学习**
    - 先在其他任务预训练，再微调目标任务；从无标签数据中自动提取标签，也叫无监督预训练。
    - 例子：自然语言中GPT的“下一个词”、BERT的“掩蔽词”预训练任务，计算机视觉的图像修复（图30-2展示图像修复的自监督学习）。
5. **主动学习**
    - 模型主动选择数据让人工标注（如选高预测不确定性的数据点），而非预先标注整个数据集，以此最大化提升模型性能（图30-3展示主动学习流程）。
6. **小样本学习**
    - 处理极小数据集（每个分类仅少数样本），常见1-shot（每类1样本）、5-shot（每类5样本），极端为零样本学习（无标签，需输入提示提供信息）；典型例子是GPT-3及相关语言模型（图30-4展示ChatGPT零样本分类）。
7. **元学习**
    - 即“学习如何学习”，让算法从数据中学习开发方法。
    - 分支方向：从监督任务数据集提取元特征（描述数据集的统计数据）；学习好的特征提取模块，通过支撑集训练优化查询样本的预测分类。
    - 图30-5展示元数据提取的元学习过程，可缩小算法和超参数搜索空间，减少小数据集的过拟合。
8. **弱监督学习**
    - 用外部标签来源为无标签数据生成标签，这类标签比人工/专家标注更嘈杂、不准确，也叫弱监督；可开发规则分类器创建弱监督标签（规则仅覆盖无标签数据集子集）。
    - 图30-6展示弱监督学习利用外部标签函数训练模型的流程，包含无标签数据集、应用标注函数、获取弱标签数据集、训练应用分类器四个步骤。
9. **半监督学习**
    - 与弱监督学习密切相关，均用未标注样本创建标签；区别是半监督学习不依赖外部标签函数，而是利用数据自身结构（如邻近已标注点的密度）标注。
    - 实践中可先弱监督标注数据子集，再用半监督学习标注未被标签函数捕获的实例；弱监督的子集PU学习（positive-unlabeled learning）仅对正样本标注学习（图30-7展示半监督学习）。
10. **自训练**
    - 介于半监督与弱监督之间，训练模型为数据集打标签（伪标签器），依赖现有模型标注但无法保证标签准确性，与弱监督、半监督相关；例子为知识蒸馏。
11. **多任务学习**
    - 在多个相关任务上训练模型，主任务搭配辅助任务（辅助任务为归纳偏置，引导模型考虑多任务假设），通过多损失函数同时优化。
    - 子类：硬参数共享（所有任务共享隐藏层和主干网络，仅输出层任务特定）、软参数共享（各任务用独立网络，通过参数层距离最小化提升相似性）；图30-8展示两种参数共享方式的区别。


### 30.1 利用有限有标签数据的补充方法
1. **多模态学习（30.1.12）**
    - 核心：区别于多任务学习（多任务/损失函数），侧重**融合多种类型输入数据**（不限两种模态）。
    - 实现方式：通过匹配损失迫使不同模态（如图像、文本）的嵌入向量相似；也可直接优化分类/回归等目标损失。
    - 实例：ImageBERT/VideoBERT用Transformer模块联合处理图像/文本、视频/文本；融合温度计（传感器1）和摄像机（传感器2）数据，将不同信号编码为同维度嵌入后拼接成输入表征。
    - 优势：多模态模型能利用更多信息，性能优于单模态模型，关键是提升潜空间表征质量（图30-8展示多任务学习参数共享，图30-9/30-10展示多模态学习流程）。

2. **归纳偏置（30.1.13）**
    - 核心：选择**归纳偏置更强的模型**，通过对数据结构做假设降低数据需求。
    - 实例：卷积网络因归纳偏置，所需数据量少于视觉Transformer。

### 30.2 技术选择建议
1. **通用兼容策略**：数据收集、数据增强、特征工程可与本章所有方法兼容；多任务学习、多模态输入也可结合各类学习策略；模型过拟合时需参考第5、6章的技术。
2. **决策流程（图30-11）**：
    - 先训练模型并评测性能，若精度不足则绘制学习曲线，判断增加数据是否有帮助。
    - 若增加数据有帮助：能收集更多数据则优先收集；无法收集则看能否人工标注，能则进一步判断人类是否能与模型互动（能→主动学习，不能→标注更多训练数据）；不能人工标注则看能否用算法标注（能→弱监督学习，不能则判断是否训练深度神经网络：是→自监督学习，否→半监督学习）。
    - 若有重新标注的数据集→迁移学习；无则→小样本学习。
    - 注：决策流程中的深色方框并非终点，需返回“评测模型性能”环节迭代优化。


