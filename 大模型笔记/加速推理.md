
### 核心背景
模型推理是用训练好的模型做预测/生成输出，提升推理性能的通用技术包括**并行化、向量化、循环分块、算子融合、量化**，本章聚焦前四类不牺牲准确性的技术，量化因可能影响精度为补充说明。

### 一、并行化（22.1）
1. **核心逻辑**：推理时将模型应用于**一批样本**（批量推理），而非逐一样本处理（按序推理），实现并行计算。
2. **图示说明**（图22-1）：按序推理一次处理一个样本（如先识别苹果，再识别T恤），批量推理可同时处理多个样本（苹果、T恤、书本、兔子），解决多样本等待的瓶颈问题。

### 二、向量化（22.2）
1. **核心逻辑**：单个步骤中对整个数据结构（数组/张量/矩阵）操作，替代for循环的迭代结构；采用CPU的**单指令多数据（SIMD）** 方式，同时执行多个操作。
2. **技术支撑**：依赖**BLAS（基础线性代数子程序库）**，NumPy、PyTorch等库内部均集成BLAS。
3. **实例对比**（图22-2）：
   - 非向量化：用for循环逐元素计算向量点积，效率低。
   - 向量化：通过PyTorch的`tensor.dot()`一次性计算点积，深度学习框架（TensorFlow/PyTorch）会自动实现向量化，提升计算效率。

### 三、循环分块（22.3）
1. **核心逻辑**：也叫循环嵌套优化，将循环的迭代空间分解为更小的“小块”，增强数据局部性；确保数据加载到缓存后，在缓存清空前完成所有相关计算。
2. **图示说明**（图22-3）：常规for循环逐行/列迭代二维数组元素，循环分块将数组分割为小块区域，先处理内部分块再跨分块循环。
3. **应用说明**：Python等高级语言不支持直接控制缓存，这类优化通常由NumPy、PyTorch等底层库处理。

### 四、算子融合（22.4）
1. **核心逻辑**：也叫循环融合，将多个独立循环合并为单个循环，减少循环控制开销、提升缓存性能、结合向量化进一步优化。
2. **图示说明**（图22-4）：将“计算数字总和”“计算数字乘积”的两个for循环，融合为一个循环完成双任务。
3. **相关概念**：重新参数化，将多操作简化为单一操作（如RepVGG架构训练时用多分支卷积，推理时重参数化为单序列卷积），打造更高效的推理架构。
4. **技术互补性**：与循环分块并不冲突——算子融合减少循环迭代次数，适用于数据全入缓存的场景；循环分块提升缓存利用率，适用于大数据组无法全入缓存的场景。

### 五、量化（22.5）
1. **核心逻辑**：将神经网络的权重/偏置从浮点数转换为离散、低精度的表征（如8位/4位整数），减小模型大小、加快执行速度、提升硬件效率。
2. **分类**：
   - 训练后量化：先全精度训练模型，再对模型量化。
   - 量化感知训练：训练过程中引入量化步骤，模型学习补偿量化影响，更易保持准确性。
3. **注意点**：量化可能降低模型准确性，因此并非本章“不牺牲准确性”的核心技术；知识蒸馏、剪枝也能提升推理速度，但会改变模型架构，超出本章讨论范围。

